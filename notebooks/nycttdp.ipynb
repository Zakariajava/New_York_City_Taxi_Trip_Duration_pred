{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9b728919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# --- Reproducible environment & lightweight utilities ---\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- Training utilities ---\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score, accuracy_score, f1_score,\n",
    "    roc_curve, precision_recall_curve, confusion_matrix, classification_report\n",
    ")\n",
    "from tqdm.auto import tqdm\n",
    "import math\n",
    "\n",
    "\n",
    "# Plot defaults: consistent sizing and readable grids\n",
    "plt.rcParams[\"figure.figsize\"] = (9, 5)\n",
    "plt.rcParams[\"axes.grid\"] = True\n",
    "plt.rcParams[\"figure.dpi\"] = 140\n",
    "\n",
    "# Keep the console clean from non-critical warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Reproducibility\n",
    "RNG_SEED = 42\n",
    "rng = np.random.default_rng(RNG_SEED)\n",
    "\n",
    "# Project paths\n",
    "TRAIN_DATASET = \"../data/train.csv\"\n",
    "TEST_DATASET = \"../data/test.csv\"\n",
    "MODEL_PATH = \"../models\"\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6faaf34",
   "metadata": {},
   "source": [
    "# Data Cleaning & Alignment\n",
    "\n",
    "Before any feature engineering or modeling, we ensure both **train** and **test** datasets share the exact same structure.  \n",
    "This involves removing columns that are not available in both sets (to avoid data leakage),  \n",
    "isolating the **target variable** (`trip_duration`), and preserving **ID columns** separately for evaluation and submission.\n",
    "\n",
    "Steps:\n",
    "1. Drop `dropoff_datetime` from the training data — it's unavailable in test and leaks target information.  \n",
    "2. Split the target column (`trip_duration`) from the training features.  \n",
    "3. Store `id` columns separately to use later when generating the submission file.  \n",
    "4. Remove `id` from features (since it has no predictive value).  \n",
    "5. Validate that train and test feature sets are perfectly aligned.  \n",
    "This ensures both datasets are **schema-consistent**, **leak-free**, and ready for feature extraction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ce42527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "df_train = pd.read_csv(TRAIN_DATASET)\n",
    "df_test = pd.read_csv(TEST_DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e97a3b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'vendor_id', 'pickup_datetime', 'dropoff_datetime',\n",
       "       'passenger_count', 'pickup_longitude', 'pickup_latitude',\n",
       "       'dropoff_longitude', 'dropoff_latitude', 'store_and_fwd_flag',\n",
       "       'trip_duration'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa4014c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'vendor_id', 'pickup_datetime', 'passenger_count',\n",
       "       'pickup_longitude', 'pickup_latitude', 'dropoff_longitude',\n",
       "       'dropoff_latitude', 'store_and_fwd_flag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0576ed4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes aligned: X_train=(1458644, 8), X_test=(625134, 8)\n",
      "Target shape: y_train=(1458644,)\n",
      "Feature columns: ['vendor_id', 'pickup_datetime', 'passenger_count', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'store_and_fwd_flag']\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Clean alignment between train and test datasets\n",
    "# ============================================================\n",
    "\n",
    "# --- 1. Drop columns from train that do not exist in test ---\n",
    "# (dropoff_datetime leaks the target information)\n",
    "df_train = df_train.drop(columns=[\"dropoff_datetime\"])\n",
    "# --- 2. Separate the target variable (trip_duration) ---\n",
    "target_col = \"trip_duration\"\n",
    "y_train = df_train[target_col]\n",
    "X_train = df_train.drop(columns=[target_col])\n",
    "# --- 3. Keep ID columns separately for later submission/evaluation ---\n",
    "train_ids = X_train[\"id\"].copy()\n",
    "test_ids = df_test[\"id\"].copy()\n",
    "# --- 4. Drop ID columns from the feature sets (not predictive) ---\n",
    "X_train = X_train.drop(columns=[\"id\"])\n",
    "X_test = df_test.drop(columns=[\"id\"])\n",
    "print(f\"Shapes aligned: X_train={X_train.shape}, X_test={X_test.shape}\")\n",
    "print(f\"Target shape: y_train={y_train.shape}\")\n",
    "print(f\"Feature columns: {X_train.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd4cb231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1458644 entries, 0 to 1458643\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count    Dtype  \n",
      "---  ------              --------------    -----  \n",
      " 0   vendor_id           1458644 non-null  int64  \n",
      " 1   pickup_datetime     1458644 non-null  object \n",
      " 2   passenger_count     1458644 non-null  int64  \n",
      " 3   pickup_longitude    1458644 non-null  float64\n",
      " 4   pickup_latitude     1458644 non-null  float64\n",
      " 5   dropoff_longitude   1458644 non-null  float64\n",
      " 6   dropoff_latitude    1458644 non-null  float64\n",
      " 7   store_and_fwd_flag  1458644 non-null  object \n",
      "dtypes: float64(4), int64(2), object(2)\n",
      "memory usage: 89.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6da4221c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['N', 'Y'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_train[\"store_and_fwd_flag\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4b9d116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the categorical flag ('N'/'Y') into a binary numeric feature (0/1)\n",
    "# 'N' → 0 means no message stored/forwarded\n",
    "# 'Y' → 1 means the trip record was stored and forwarded\n",
    "for df in (X_train, X_test):\n",
    "    df[\"store_and_fwd_flag\"] = df[\"store_and_fwd_flag\"].map({\"N\": 0, \"Y\": 1}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90b2732a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2016-03-14 17:24:55\n",
       "1    2016-06-12 00:43:35\n",
       "2    2016-01-19 11:35:24\n",
       "3    2016-04-06 19:32:31\n",
       "4    2016-03-26 13:30:55\n",
       "Name: pickup_datetime, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_train[\"pickup_datetime\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdb6642e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Datetime feature engineering for pickup_datetime\n",
    "# ============================================================\n",
    "\n",
    "def add_pickup_datetime_features(df: pd.DataFrame, col: str = \"pickup_datetime\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Expand the pickup datetime column into a set of meaningful numerical features.\n",
    "\n",
    "    This transformation:\n",
    "    - Parses the raw timestamp into a proper datetime object.\n",
    "    - Extracts calendar/time components (year, month, day, hour, minute, weekday).\n",
    "    - Adds a weekend indicator.\n",
    "    - Adds cyclic encodings for hour-of-day and day-of-week to capture periodic patterns.\n",
    "    - Drops the original datetime column once all features are derived.\n",
    "\n",
    "    The function returns a new DataFrame with the additional columns.\n",
    "    \"\"\"\n",
    "    # Parse the datetime column (errors coerced to NaT to avoid hard crashes on bad rows)\n",
    "    dt = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "\n",
    "    # Basic calendar components\n",
    "    df[\"pickup_year\"] = dt.dt.year\n",
    "    df[\"pickup_month\"] = dt.dt.month\n",
    "    df[\"pickup_day\"] = dt.dt.day\n",
    "    df[\"pickup_hour\"] = dt.dt.hour\n",
    "    df[\"pickup_minute\"] = dt.dt.minute\n",
    "    df[\"pickup_dayofweek\"] = dt.dt.dayofweek  # 0 = Monday, 6 = Sunday\n",
    "\n",
    "    # Weekend flag: 1 if Saturday/Sunday, else 0\n",
    "    df[\"is_weekend\"] = (df[\"pickup_dayofweek\"] >= 5).astype(int)\n",
    "\n",
    "    # Cyclic encoding for hour of day (24-hour cycle)\n",
    "    df[\"pickup_hour_sin\"] = np.sin(2 * np.pi * df[\"pickup_hour\"] / 24)\n",
    "    df[\"pickup_hour_cos\"] = np.cos(2 * np.pi * df[\"pickup_hour\"] / 24)\n",
    "\n",
    "    # Cyclic encoding for day of week (7-day cycle)\n",
    "    df[\"pickup_dow_sin\"] = np.sin(2 * np.pi * df[\"pickup_dayofweek\"] / 7)\n",
    "    df[\"pickup_dow_cos\"] = np.cos(2 * np.pi * df[\"pickup_dayofweek\"] / 7)\n",
    "\n",
    "    # Drop the original raw datetime column to keep the feature space purely numeric\n",
    "    df = df.drop(columns=[col])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3329f525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the same transformation to both train and test feature sets\n",
    "X_train = add_pickup_datetime_features(X_train, col=\"pickup_datetime\")\n",
    "X_test = add_pickup_datetime_features(X_test, col=\"pickup_datetime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c65c2a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>pickup_year</th>\n",
       "      <th>pickup_month</th>\n",
       "      <th>pickup_day</th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>pickup_minute</th>\n",
       "      <th>pickup_dayofweek</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>pickup_hour_sin</th>\n",
       "      <th>pickup_hour_cos</th>\n",
       "      <th>pickup_dow_sin</th>\n",
       "      <th>pickup_dow_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.982155</td>\n",
       "      <td>40.767937</td>\n",
       "      <td>-73.964630</td>\n",
       "      <td>40.765602</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.980415</td>\n",
       "      <td>40.738564</td>\n",
       "      <td>-73.999481</td>\n",
       "      <td>40.731152</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.979027</td>\n",
       "      <td>40.763939</td>\n",
       "      <td>-74.005333</td>\n",
       "      <td>40.710087</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-74.010040</td>\n",
       "      <td>40.719971</td>\n",
       "      <td>-74.012268</td>\n",
       "      <td>40.706718</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.973053</td>\n",
       "      <td>40.793209</td>\n",
       "      <td>-73.972923</td>\n",
       "      <td>40.782520</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vendor_id  passenger_count  pickup_longitude  pickup_latitude  \\\n",
       "0          2                1        -73.982155        40.767937   \n",
       "1          1                1        -73.980415        40.738564   \n",
       "2          2                1        -73.979027        40.763939   \n",
       "3          2                1        -74.010040        40.719971   \n",
       "4          2                1        -73.973053        40.793209   \n",
       "\n",
       "   dropoff_longitude  dropoff_latitude  store_and_fwd_flag  pickup_year  \\\n",
       "0         -73.964630         40.765602                   0         2016   \n",
       "1         -73.999481         40.731152                   0         2016   \n",
       "2         -74.005333         40.710087                   0         2016   \n",
       "3         -74.012268         40.706718                   0         2016   \n",
       "4         -73.972923         40.782520                   0         2016   \n",
       "\n",
       "   pickup_month  pickup_day  pickup_hour  pickup_minute  pickup_dayofweek  \\\n",
       "0             3          14           17             24                 0   \n",
       "1             6          12            0             43                 6   \n",
       "2             1          19           11             35                 1   \n",
       "3             4           6           19             32                 2   \n",
       "4             3          26           13             30                 5   \n",
       "\n",
       "   is_weekend  pickup_hour_sin  pickup_hour_cos  pickup_dow_sin  \\\n",
       "0           0        -0.965926        -0.258819        0.000000   \n",
       "1           1         0.000000         1.000000       -0.781831   \n",
       "2           0         0.258819        -0.965926        0.781831   \n",
       "3           0        -0.965926         0.258819        0.974928   \n",
       "4           1        -0.258819        -0.965926       -0.974928   \n",
       "\n",
       "   pickup_dow_cos  \n",
       "0        1.000000  \n",
       "1        0.623490  \n",
       "2        0.623490  \n",
       "3       -0.222521  \n",
       "4       -0.222521  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fce64943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     455\n",
      "1     663\n",
      "2    2124\n",
      "3     429\n",
      "4     435\n",
      "Name: trip_duration, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b996b159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map vendor_id from {1,2} to {0,1}\n",
    "for df in (X_train, X_test):\n",
    "    df[\"vendor_id\"] = df[\"vendor_id\"].map({1: 0, 2: 1}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "37bb562d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Split training data into train/validation subsets\n",
    "# ============================================================\n",
    "\n",
    "# We'll keep aside a small fraction for internal validation.\n",
    "# This helps us tune hyperparameters and check overfitting.\n",
    "X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
    "    X_train, y_train,\n",
    "    test_size=0.02,             # 2% for validation\n",
    "    random_state=RNG_SEED,      \n",
    "    shuffle=True\n",
    ")\n",
    "X_train_main, X_test_from_train, y_train_main, y_test_from_train = train_test_split(\n",
    "    X_train_split, y_train_split,\n",
    "    test_size=0.02,\n",
    "    random_state=RNG_SEED,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb5862b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train main: (1400881, 18) (1400881,)\n",
      "Val: (29173, 18) (29173,)\n",
      "Test-from-train: (28590, 18) (28590,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train main:\", X_train_main.shape, y_train_main.shape)\n",
    "print(\"Val:\", X_val.shape, y_val.shape)\n",
    "print(\"Test-from-train:\", X_test_from_train.shape, y_test_from_train.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
