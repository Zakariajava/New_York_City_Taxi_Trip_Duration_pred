{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b728919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# --- Reproducible environment & lightweight utilities ---\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import Iterable, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import FunctionTransformer, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# --- Training utilities ---\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score, accuracy_score, f1_score,\n",
    "    roc_curve, precision_recall_curve, confusion_matrix, classification_report\n",
    ")\n",
    "from tqdm.auto import tqdm\n",
    "import math\n",
    "import os\n",
    "\n",
    "# Plot defaults: consistent sizing and readable grids\n",
    "plt.rcParams[\"figure.figsize\"] = (9, 5)\n",
    "plt.rcParams[\"axes.grid\"] = True\n",
    "plt.rcParams[\"figure.dpi\"] = 140\n",
    "\n",
    "# Keep the console clean from non-critical warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Reproducibility\n",
    "RNG_SEED = 42\n",
    "rng = np.random.default_rng(RNG_SEED)\n",
    "\n",
    "# Project paths\n",
    "TRAIN_DATASET = \"../data/train.csv\"\n",
    "TEST_DATASET = \"../data/test.csv\"\n",
    "MODEL_PATH = \"../models\"\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6faaf34",
   "metadata": {},
   "source": [
    "# Data Cleaning & Alignment\n",
    "\n",
    "Before any feature engineering or modeling, we ensure both **train** and **test** datasets share the exact same structure.  \n",
    "This involves removing columns that are not available in both sets (to avoid data leakage),  \n",
    "isolating the **target variable** (`trip_duration`), and preserving **ID columns** separately for evaluation and submission.\n",
    "\n",
    "Steps:\n",
    "1. Drop `dropoff_datetime` from the training data â€” it's unavailable in test and leaks target information.  \n",
    "2. Split the target column (`trip_duration`) from the training features.  \n",
    "3. Store `id` columns separately to use later when generating the submission file.  \n",
    "4. Remove `id` from features (since it has no predictive value).  \n",
    "5. Validate that train and test feature sets are perfectly aligned.  \n",
    "This ensures both datasets are **schema-consistent**, **leak-free**, and ready for feature extraction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ce42527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "df_train = pd.read_csv(TRAIN_DATASET)\n",
    "df_test = pd.read_csv(TEST_DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e97a3b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'vendor_id', 'pickup_datetime', 'dropoff_datetime',\n",
       "       'passenger_count', 'pickup_longitude', 'pickup_latitude',\n",
       "       'dropoff_longitude', 'dropoff_latitude', 'store_and_fwd_flag',\n",
       "       'trip_duration'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa4014c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'vendor_id', 'pickup_datetime', 'passenger_count',\n",
       "       'pickup_longitude', 'pickup_latitude', 'dropoff_longitude',\n",
       "       'dropoff_latitude', 'store_and_fwd_flag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0576ed4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes aligned: X_train=(1458644, 8), X_test=(625134, 8)\n",
      "Target shape: y_train=(1458644,)\n",
      "Feature columns: ['vendor_id', 'pickup_datetime', 'passenger_count', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'store_and_fwd_flag']\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Clean alignment between train and test datasets\n",
    "# ============================================================\n",
    "\n",
    "# --- 1. Drop columns from train that do not exist in test ---\n",
    "# (dropoff_datetime leaks the target information)\n",
    "df_train = df_train.drop(columns=[\"dropoff_datetime\"])\n",
    "# --- 2. Separate the target variable (trip_duration) ---\n",
    "target_col = \"trip_duration\"\n",
    "y_train = df_train[target_col]\n",
    "X_train = df_train.drop(columns=[target_col])\n",
    "# --- 3. Keep ID columns separately for later submission/evaluation ---\n",
    "train_ids = X_train[\"id\"].copy()\n",
    "test_ids = df_test[\"id\"].copy()\n",
    "# --- 4. Drop ID columns from the feature sets (not predictive) ---\n",
    "X_train = X_train.drop(columns=[\"id\"])\n",
    "X_test = df_test.drop(columns=[\"id\"])\n",
    "print(f\"Shapes aligned: X_train={X_train.shape}, X_test={X_test.shape}\")\n",
    "print(f\"Target shape: y_train={y_train.shape}\")\n",
    "print(f\"Feature columns: {X_train.columns.tolist()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
